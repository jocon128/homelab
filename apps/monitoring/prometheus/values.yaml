alertmanager:
  alertmanagerSpec:
    image:
      registry: quay.io
      repository: prometheus/alertmanager
      tag: v0.27.0
    nodeSelector:
      kubernetes.io/arch: amd64
    replicas: 1
    resources:
      limits:
        cpu: 250m
        memory: 512Mi
      requests:
        cpu: 80m
        memory: 256Mi
  apiVersion: v2
  config:
    route:
      routes:
        - matchers:
            - alertname =~ "InfoInhibitor|Watchdog"
  ingress:
    enabled: false
  ingressPerReplica:
    enabled: false
    tlsSecretPerReplica:
      enabled: false
      prefix: alertmanager
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  service:
    externalTrafficPolicy: Cluster
    nodePort: 30903
    port: 9093
    targetPort: 9093
    type: ClusterIP
  serviceAccount:
    create: true
  serviceMonitor:
    enableHttp2: true
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    sampleLimit: 0
    selfMonitor: true
    targetLimit: 0
  servicePerReplica:
    enabled: false
    externalTrafficPolicy: Cluster
    nodePort: 30904
    port: 9093
    targetPort: 9093
    type: ClusterIP
  tplConfig: false
cleanPrometheusOperatorObjectNames: false
defaultRules:
  rules:
    alertmanager: true
    configReloaders: true
    etcd: false
    general: true
    k8s: true
    kubeApiserverAvailability: false
    kubeApiserverBurnrate: false
    kubeApiserverHistogram: false
    kubeApiserverSlos: false
    kubeControllerManager: false
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubeProxy: true
    kubeSchedulerAlerting: true
    kubeSchedulerRecording: true
    kubeStateMetrics: true
    kubelet: true
    kubernetesApps: false
    kubernetesResources: false
    kubernetesStorage: false
    kubernetesSystem: false
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
grafana:
  adminPassword: <path:kv/data/kube-prometheus#grafana-admin-password>
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - disableDeletion: true
          editable: true
          folder: services
          name: services
          options:
            path: /var/lib/grafana/dashboards/services
          orgId: 1
          type: file
        - disableDeletion: true
          editable: true
          folder: kubernetes
          name: kubernetes
          options:
            path: /var/lib/grafana/dashboards/kubernetes
          orgId: 1
          type: file
        - disableDeletion: true
          editable: true
          folder: data
          name: data
          options:
            path: /var/lib/grafana/dashboards/data
          orgId: 1
          type: file
        - disableDeletion: true
          editable: true
          folder: networking
          name: networking
          options:
            path: /var/lib/grafana/dashboards/networking
          orgId: 1
          type: file
  dashboards:
    kubernetes:
      apiServer:
        datasource: Prometheus
        gnetId: 15761
        revision: 11
      coreDns:
        datasource: Prometheus
        gnetId: 15762
        revision: 10
      globalView:
        datasource: Prometheus
        gnetId: 15757
        revision: 22
      namespaces:
        datasource: Prometheus
        gnetId: 15758
        revision: 15
      nodes:
        datasource: Prometheus
        gnetId: 15759
        revision: 14
      pods:
        datasource: Prometheus
        gnetId: 15760
        revision: 15
      pvcs:
        datasource: Prometheus
        gnetId: 13646
        revision: 2
    services:
      argocdMonitoring:
        datasource: Prometheus
        gnetId: 14584
        revision: 1
      grafanaImageRenderer:
        datasource: Prometheus
        gnetId: 12203
        revision: 2
      nvidiaMonitoring:
        datasource: Prometheus
        gnetId: 14574
        revision: 8
      vaultMonitoring:
        datasource: Prometheus
        gnetId: 15124
        revision: 2
      Sonarr:
        datasource: Prometheus
        gnetId: 12530
        revision: 2
      Uptimekuma:
        datasource: Prometheus
        gnetId: 18278
        revision: 1
    networking:
      calicoMonitoring:
        datasource: Prometheus
        gnetId: 12175
        revision: 5
      certExporter:
        datasource: Prometheus
        gnetId: 12170
        revision: 1
      certExpiration:
        datasource: Prometheus
        gnetId: 13922
        revision: 3
      nginxIngress:
        datasource: Prometheus
        gnetId: 14314
        revision: 2
      externalDNS:
        datasource: Prometheus
        gnetId: 15038
        revision: 1
    data:
      Milvus:
        datasource: Prometheus
        url: https://raw.githubusercontent.com/milvus-io/milvus/2.3.0/deployments/monitor/grafana/milvus-dashboard.json
      redisMonitoring:
        datasource: Prometheus
        gnetId: 763
        revision: 5
      postgresMonitoring:
        datasource: Prometheus
        gnetId: 12485
        revision: 1
  defaultDashboardsTimezone: Australia/Brisbane
  env:
    GF_RENDERING_CALLBACK_URL: http://kube-prometheus-grafana.monitoring.svc.cluster.local
    GF_RENDERING_SERVER_URL: http://grafana-image-renderer.monitoring.svc.cluster.local/render
  namespaceOverride: monitoring
  plugins:
    - grafana-image-renderer
    - grafana-piechart-panel
    - grafana-clock-panel
  service:
    enabled: true
    portName: service
    type: ClusterIP
  serviceMonitor:
    scrapeTimeout: 60s
kube-state-metrics:
  metricLabelsAllowlist:
    - "pods=[*]"
    - "deployments=[*]"
    - "statefulsets=[*]"
    - "persistentvolumeclaims=[*]"
  prometheus:
    monitor:
      relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels: ["__meta_kubernetes_pod_node_name"]
          targetLabel: kubernetes_node
kubeApiServer:
  enabled: false
kubeControllerManager:
  enabled: false
kubeDns:
  enabled: false
kubeEtcd:
  enabled: false
kubeProxy:
  enabled: false
kubeScheduler:
  enabled: false
kubeStateMetrics:
  enabled: true
kubelet:
  serviceMonitor:
    metricRelabelings:
      # k3s exposes all metrics on all endpoints, relabel jobs that belong to other components
      - sourceLabels: [__name__]
        regex: "scheduler_(.+)"
        targetLabel: "job"
        replacement: "kube-scheduler"
        action: replace
      - sourceLabels: [__name__]
        regex: "kubeproxy_(.+)"
        targetLabel: "job"
        replacement: "kube-proxy"
        action: replace
        # Remove duplicate metrics
      - sourceLabels: ["__name__"]
        regex: "(apiserver_audit|apiserver_client|apiserver_delegated|apiserver_envelope|apiserver_storage|apiserver_webhooks|authentication_token|cadvisor_version|container_blkio|container_cpu|container_fs|container_last|container_memory|container_network|container_oom|container_processes|container|csi_operations|disabled_metric|get_token|go|hidden_metric|kubelet_certificate|kubelet_cgroup|kubelet_container|kubelet_containers|kubelet_cpu|kubelet_device|kubelet_graceful|kubelet_http|kubelet_lifecycle|kubelet_managed|kubelet_node|kubelet_pleg|kubelet_pod|kubelet_run|kubelet_running|kubelet_runtime|kubelet_server|kubelet_started|kubelet_volume|kubernetes_build|kubernetes_feature|machine_cpu|machine_memory|machine_nvm|machine_scrape|node_namespace|plugin_manager|prober_probe|process_cpu|process_max|process_open|process_resident|process_start|process_virtual|registered_metric|rest_client|scrape_duration|scrape_samples|scrape_series|storage_operation|volume_manager|volume_operation|workqueue)_(.+)"
        action: keep
      - sourceLabels: ["node"]
        targetLabel: instance
        action: replace
    cAdvisor: true
    cAdvisorMetricRelabelings:
      - action: drop
        regex: container_cpu_(cfs_throttled_seconds_total|load_average_10s|system_seconds_total|user_seconds_total)
        sourceLabels:
          - __name__
      - action: drop
        regex: container_fs_(io_current|io_time_seconds_total|io_time_weighted_seconds_total|reads_merged_total|sector_reads_total|sector_writes_total|writes_merged_total)
        sourceLabels:
          - __name__
      - action: drop
        regex: container_memory_(mapped_file|swap)
        sourceLabels:
          - __name__
      - action: drop
        regex: container_(file_descriptors|tasks_state|threads_max)
        sourceLabels:
          - __name__
      - action: drop
        regex: container_spec.*
        sourceLabels:
          - __name__
      - action: drop
        regex: .+;
        sourceLabels:
          - id
          - pod
    cAdvisorRelabelings:
      - action: replace
        sourceLabels:
          - __metrics_path__
        targetLabel: metrics_path
    https: true
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    probes: true
    probesRelabelings:
      - action: replace
        sourceLabels:
          - __metrics_path__
        targetLabel: metrics_path
    relabelings:
      - action: replace
        sourceLabels:
          - __metrics_path__
        targetLabel: metrics_path
    resource: false
    resourcePath: /metrics/resource/v1alpha1
    resourceRelabelings:
      - action: replace
        sourceLabels:
          - __metrics_path__
        targetLabel: metrics_path
    sampleLimit: 0
    targetLimit: 0
namespaceOverride: monitoring
nodeExporter:
  enabled: true
prometheus:
  enabled: true
  ingress:
    enabled: false
  ingressPerReplica:
    enabled: false
    tlsSecretPerReplica:
      enabled: false
      prefix: prometheus
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  prometheusSpec:
    additionalScrapeConfigs:
      - authorization:
          credentials: <path:kv/data/ha#auth-token>
        job_name: hass
        metrics_path: /api/prometheus
        scheme: http
        scrape_interval: 60s
        static_configs:
          - targets:
              - homeassistant.homeassistant.svc.cluster.local:80
      - job_name: grafana-image-rendering-service
        static_configs:
          - targets:
              - grafana-image-renderer.monitoring.svc.cluster.local:80
      - job_name: argocd
        metrics_path: /metrics
        static_configs:
          - targets:
              - argocd-metrics.argocd.svc.cluster.local:8082
              - argocd-server-metrics.argocd.svc.cluster.local:8083
              - argocd-repo-server.argocd.svc.cluster.local:8084
      - job_name: "uptime"
        scrape_interval: 30s
        scheme: http
        static_configs:
          - targets:
              - kuma-internal.monitoring.svc.cluster.local:80
        basic_auth:
          username: <path:kv/data/kuma#username>
          password: <path:kv/data/kuma#password>
    allowOverlappingBlocks: false
    arbitraryFSAccessThroughSMs: false
    disableCompaction: false
    enableAdminAPI: false
    enableRemoteWriteReceiver: false
    enforcedLabelLimit: false
    enforcedLabelNameLengthLimit: false
    enforcedLabelValueLengthLimit: false
    enforcedSampleLimit: false
    enforcedTargetLimit: false
    hostNetwork: false
    ignoreNamespaceSelectors: false
    image:
      registry: quay.io
      repository: prometheus/prometheus
      tag: v3.1.0
    listenLocal: false
    logFormat: logfmt
    logLevel: info
    minReadySeconds: 0
    nodeSelector:
      kubernetes.io/arch: amd64
    overrideHonorLabels: false
    overrideHonorTimestamps: false
    paused: false
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    podMonitorSelectorNilUsesHelmValues: false
    portName: http-web
    probeSelectorNilUsesHelmValues: false
    prometheusExternalLabelNameClear: false
    queryLogFile: false
    remoteWriteDashboards: false
    replicaExternalLabelNameClear: false
    replicas: 1
    resources:
      limits:
        cpu: 600m
        memory: 2Gi
      requests:
        cpu: 130m
        memory: 512Mi
    retention: 10d
    routePrefix: /
    ruleSelector:
      matchExpressions:
        - key: prometheus
          operator: In
          values:
            - longhorn
    ruleSelectorNilUsesHelmValues: false
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
    serviceMonitorNamespaceSelector:
      matchLabels:
        prometheus: enabled
    serviceMonitorSelectorNilUsesHelmValues: false
    shards: 1
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 30Gi
          storageClassName: longhorn
    walCompression: true
  service:
    externalTrafficPolicy: Cluster
    nodePort: 30090
    port: 9090
    publishNotReadyAddresses: false
    targetPort: 9090
    type: ClusterIP
  serviceAccount:
    create: true
  serviceMonitor:
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    sampleLimit: 0
    selfMonitor: true
    targetLimit: 0
  servicePerReplica:
    enabled: false
    externalTrafficPolicy: Cluster
    nodePort: 30091
    port: 9090
    targetPort: 9090
    type: ClusterIP
  thanosIngress:
    enabled: false
    nodePort: 30901
    servicePort: 10901
  thanosService:
    clusterIP: None
    enabled: false
    externalTrafficPolicy: Cluster
    httpNodePort: 30902
    httpPort: 10902
    httpPortName: http
    nodePort: 30901
    port: 10901
    portName: grpc
    targetHttpPort: http
    targetPort: grpc
    type: ClusterIP
  thanosServiceExternal:
    enabled: false
    externalTrafficPolicy: Cluster
    httpNodePort: 30902
    httpPort: 10902
    httpPortName: http
    nodePort: 30901
    port: 10901
    portName: grpc
    targetHttpPort: http
    targetPort: grpc
    type: LoadBalancer
  thanosServiceMonitor:
    enabled: false
prometheus-node-exporter:
  extraArgs:
    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
  podLabels:
    jobLabel: node-exporter
  prometheus:
    monitor:
      enabled: true
      jobLabel: jobLabel
      labelLimit: 0
      labelNameLengthLimit: 0
      labelValueLengthLimit: 0
      sampleLimit: 0
      targetLimit: 0
  rbac:
    pspEnabled: false
  releaseLabel: true
  service:
    portName: http-metrics
prometheusOperator:
  tlsProxy:
    enabled: false
  tls:
    enabled: false
    internalPort: 10250
    tlsMinVersion: VersionTLS13
  admissionWebhooks:
    certManager:
      enabled: false
    enabled: false
    failurePolicy: ""
    patch:
      enabled: false
    timeoutSeconds: 10
  containerSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
  enabled: true
  hostNetwork: false
  image:
    pullPolicy: IfNotPresent
    registry: quay.io
    repository: prometheus-operator/prometheus-operator
    tag: v0.77.1
  kubeletService:
    enabled: false
  namespaces:
    additional:
      - kube-system
      - vault
      - agones-system
      - milvus-operator
      - monitoring
    releaseNamespace: true
  networkPolicy:
    enabled: false
  nodeSelector:
    kubernetes.io/arch: amd64
  prometheusConfigReloader:
    image:
      registry: quay.io
      repository: prometheus-operator/prometheus-config-reloader
      tag: v0.77.1
    resources:
      limits:
        cpu: 80m
        memory: 160Mi
      requests:
        cpu: 40m
        memory: 80Mi
  resources:
    limits:
      cpu: 400m
      memory: 1Gi
    requests:
      cpu: 200m
      memory: 512Mi
  securityContext:
    fsGroup: 65534
    runAsGroup: 65534
    runAsNonRoot: true
    runAsUser: 65534
  service:
    externalTrafficPolicy: Cluster
    nodePort: 30080
    nodePortTls: 30443
    type: ClusterIP
  serviceAccount:
    create: true
  serviceMonitor:
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    sampleLimit: 0
    selfMonitor: true
    targetLimit: 0
  thanosImage:
    registry: quay.io
    repository: thanos/thanos
    tag: v0.36.1
  verticalPodAutoscaler:
    enabled: false
    updatePolicy:
      updateMode: Auto
thanosRuler:
  enabled: false
  ingress:
    enabled: false
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
  service:
    externalTrafficPolicy: Cluster
    nodePort: 30905
    port: 10902
    targetPort: 10902
    type: ClusterIP
  serviceAccount:
    create: true
  serviceMonitor:
    labelLimit: 0
    labelNameLengthLimit: 0
    labelValueLengthLimit: 0
    sampleLimit: 0
    selfMonitor: true
    targetLimit: 0
  thanosRulerSpec:
    image:
      registry: quay.io
      repository: thanos/thanos
      tag: v0.36.1
    listenLocal: false
    logFormat: logfmt
    logLevel: info
    nodeSelector:
      kubernetes.io/arch: amd64
    paused: false
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    portName: web
    replicas: 1
    resources:
      limits:
        cpu: 220m
        memory: 512Mi
      requests:
        cpu: 140m
        memory: 128Mi
    retention: 24h
    routePrefix: /
    ruleSelectorNilUsesHelmValues: false
    securityContext:
      fsGroup: 2000
      runAsGroup: 2000
      runAsNonRoot: true
      runAsUser: 1000
